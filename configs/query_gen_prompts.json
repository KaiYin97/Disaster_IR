{
    "qa_task": "Brainstorm a list of useful text retrieval tasks where the goal is: Given a user question, retrieve passages that directly answer the question. Here are a few examples: Given a question about evacuation procedures during a flood, retrieve a passage that explains the steps involved. Given a question about the cause of infrastructure failure in a disaster, retrieve a passage identifying the cause. Given a question about relief funding timelines, retrieve a passage providing the relevant information. Guidelines: Each task description should be one sentence that clearly describes the user question and the kind of answer passages to be retrieved. Focus on real-world domains like disaster planning, relief logistics, early warning systems, community impact, government response, etc. Your output should be a Json list of 3 strings, each describing a distinct and useful text retrieval task. Only output the list. Be creative. No explanations or additional content.",
    "qa_query": "You have been assigned a retrieval task: {task}, Your mission is to write one text retrieval example for this task in JSON format. The JSON object must contain the following keys: - user_query: a string, a random user search query specified by the retrieval task. - positive_document: a string, a relevant document for the user query. - hard_negative_document: a string, a hard negative document that only appears relevant to the query. Please adhere to the following guidelines: - The user_query should be {query_length}, {clarity}. - All documents must be created independent of the query. Avoid copying the query verbatim. It is acceptable if some parts of the positive_document are not topically related to the query. - All documents should be {num_words} long. - The hard_negative_document contains some useful information, but it should be less useful or comprehensive compared to the positive_document. - Do not provide any explanation in any document on why it is relevant or not relevant to the query. The query and documents must be realistic and inspired by real-world content (e.g., disaster management). All generated content should be in English no matter the provided content language is. - Both the query and documents require {difficulty} level education to understand. Your output must always be a JSON object only, do not explain yourself or output anything else. Be creative!",
    
    "sts_task": "Brainstorm a list of similar sentence retrieval tasks where the goal is: Given a sentence, retrieve other sentences that express the same or very similar meaning (paraphrases or semantically equivalent expressions). Here are a few examples to inspire your ideas: Given a sentence describing the impact of a flood, retrieve other sentences that paraphrase or closely restate the same impact. Given a sentence about the steps taken during emergency evacuation, retrieve sentences that express the same process using different wording. Given a sentence about climate-related disasters increasing in frequency, retrieve other sentences conveying the same trend. Given a factual statement about relief distribution, retrieve sentences that express the same fact using alternate phrasing. Guidelines: Each task should be written in one sentence and describe the kind of sentence (source) and what type of similar sentences should be retrieved. Focus on disaster-related themes such as risk, policy, action, climate, or aid—but vary topics for diversity. Your output should be a Json list of about 3 strings, each one describing a distinct similar sentence retrieval task. Output the list only. No explanations. Be creative and precise.",
    "sts_query": "You have been assigned a similar sentence retrieval task: {task}. Your mission is to write one example for this task in JSON format. The JSON object must contain: query: a single sentence that expresses a specific idea. positive: a sentence that expresses the same meaning as the query (semantic equivalence or high similarity). hard_negative: a sentence that is topically related but conveys a different meaning or a different angle (not a paraphrase).Guidelines: The query should be {query_length}, {clarity}. The query and positive should be semantically equivalent, possibly using different wording or structure. The hard negative should appear similar or related in topic but should not mean the same thing. Avoid copy-paste or trivial rewordings—be realistic and diverse. Use examples inspired by real-world disaster-related content: emergency protocols, environmental impact, infrastructure, humanitarian response, etc. All positive and negative documents should be {num_words} long. All generated content should be in English no matter the provided content language is. Both the query and documents must be understandable with {difficulty} level education. Output only a single JSON object. No explanation. Make it high-quality and realistic!",
   
    "fc_task": "Brainstorm a list of fact-checking retrieval tasks where the goal is: Given a claim, retrieve documents that either support or refute the claim, while distinguishing them from topically similar documents that do not address the claim's veracity. Here are a few examples to guide your ideas: Given a claim about the effectiveness of early warning systems during floods, retrieve documents that either support or refute the claim. Given a claim about the number of people displaced by a recent earthquake, retrieve evidence that verifies or challenges it. Given a claim about the government's relief distribution timeline, retrieve text that affirms or contradicts the stated timeline. Given a claim about the relationship between climate change and disaster frequency, retrieve relevant supporting or refuting content. Guidelines: Each task should be one sentence and describe what the claim is about and what kind of evidence is needed (support or refute). Base the topics on real-world domains such as disaster management, humanitarian aid, policy, climate, health impacts, etc. The tasks should vary in specificity and format (e.g., statistical claim, causal claim, factual assertion). Your output should be a Json list of about 3 strings, each string representing a distinct fact-checking retrieval task. Output only the list. No explanations. Be creative and diverse in topic!",
    "fc_query": "You have been assigned a fact-checking retrieval task: {task} Your mission is to write one fact-checking retrieval instance in JSON format. The JSON object must contain: claim: a short, factual or semi-factual statement (assertion) related to the task. positive_document: a paragraph that supports or refutes the claim. hard_negative_document: a paragraph that is topically relevant but does not support or refute the claim. Guidelines: The claim should be {query_length}, {clarity}. The positive document must clearly support or refute the claim—either is acceptable. The hard negative document should be closely related in topic but not contribute to fact-checking the claim. The claim should be clear, concise, and specific—not overly vague or too broad. Use examples from realistic disaster-related content: climate events, emergency response, humanitarian relief, damage estimates, etc. All positive and negative documents should be {num_words} long. All generated content should be in English no matter the provided content language is. Both the claim and documents must be understandable with {difficulty} level education. Output only a single JSON object. No additional text. Be precise and creative!",
  
    "nli_task": "Brainstorm a list of Natural Language Inference (NLI) retrieval tasks. In these tasks, the objective is: Given a premise sentence from a paragraph (e.g., about disaster management), retrieve a hypothesis sentence that is logically entailed by the premise. Here are a few examples to inspire your creativity: Given a sentence describing a government emergency response, retrieve a hypothesis that reflects an outcome or implication of that action. Given a statement about climate-induced hazards, retrieve a hypothesis summarizing the likely impact. Given a factual description of infrastructure damage, retrieve a hypothesis about the services affected. Given a claim about disaster preparedness strategies, retrieve a hypothesis that is logically supported by it. Guidelines: Each task description should be one sentence and should clearly specify the type of premise and the nature of the entailed hypothesis. Tasks should be generalizable across topics but inspired by domains such as climate, crisis response, risk, logistics, etc. Be diverse in topic and formality: from news-like to academic to conversational. Your output should be a Json list of about 3 strings, each describing a different NLI retrieval task. Output only the list of task descriptions, no explanations.",
    "nli_query": "You have been assigned an NLI retrieval task: {task}. Your mission is to write one example for this task in JSON format. The JSON object must include: premise: a sentence drawn or inspired from a paragraph (e.g., about disaster management). entailed_hypothesis: a sentence that must logically follow from the premise. contradiction: a sentence that clearly contradicts the premise. neutral: a sentence that is related to the premise but not necessarily implied by it. Guidelines: The premise should be {query_length}, {clarity}. Use realistic examples from domains like climate risk, emergency response, infrastructure, health, or logistics, etc. Ensure the entailed hypothesis is non-trivial and clearly follows from the premise. The contradiction must directly oppose a claim in the premise. The neutral sentence should be relevant in topic but not logically inferable from the premise. Avoid word-for-word overlap between the sentences unless necessary for clarity. entailed_hypothesis, contradiction, and neutral should be {num_words} long. All generated content should be in English no matter the provided content language is. All contents require {difficulty} level education to understand and should be diverse in terms of topic and length. Output a single JSON object only. Do not explain yourself or add anything else. Be creative and accurate!",
  
    "ner_task": "Brainstorm a list of entity retrieval tasks where the goal is: Given a query that contains one or more entities (e.g., organizations, locations, people, events), retrieve a passage that contains relevant and informative content about those entities. Here are a few examples to inspire your thinking: Given a query mentioning the “National Disaster Response Force,” retrieve a passage describing its role or actions. Given a query about “Cyclone Fani,” retrieve a passage that describes its impact or government response. Given a query referencing “Red Cross,” retrieve a passage detailing its involvement in relief efforts. Given a query about “UNDRR” (United Nations Office for Disaster Risk Reduction), retrieve text explaining its disaster management strategies. Guidelines: Each task should describe a situation where an entity is referenced and information about that entity should be retrieved. Focus on disaster-related entities such as government agencies, international organizations, major events, response teams, infrastructure units, or named locations. Each task should be a single sentence describing the kind of entity and the type of information to retrieve. Your output should be a Json list of about 3 strings, each describing a different entity retrieval task. No explanations. Be creative and precise.",
    "ner_query": "ou have been assigned an entity retrieval task: {task}. Your mission is to write one example for this task in JSON format. The JSON object must contain: query: a sentence that includes one or more entities relevant to the disaster domain. positive_document: a passage that provides relevant and informative content about the mentioned entity or entities. hard_negative_document: a passage that is topically related but does not provide useful information about the mentioned entities. Guidelines: The query should be {query_length}, {clarity}. The entity in the query should be clearly mentioned and recognizable. The positive_document must offer substantial, relevant content about the entity (e.g., its role, actions, impact). The hard_negative_document should be from the same general topic or paragraph, but not about the entity in question. Use examples drawn or inspired from paragraphs related to disaster management (e.g., policy, aid, emergency action, environmental events). All positive and negative documents should be {num_words} long. All generated content should be in English no matter the provided content language is. Output must be a single JSON object only. No explanations, no extra formatting. Be clear, realistic, and informative.",
  
    "tw_task": "Brainstorm a list of entity retrieval tasks where the goal is to retrieve tweets that mention or provide relevant information about one or more entities (e.g., organizations, people, locations, events) found in the query.Here are a few examples to inspire your thinking: Given a query referencing “UNICEF,” retrieve tweets about their emergency relief efforts. Given a query about “Cyclone Mocha,” retrieve tweets reporting its impact or aftermath. Given a query that mentions “World Health Organization,” retrieve tweets that discuss their role in disaster health responses. Given a query with “Manila,” retrieve tweets about disaster conditions or relief actions in that location. Guidelines: Each task should be a single sentence describing a situation where an entity is referenced and tweets related to that entity should be retrieved. Focus on disaster-related entities such as emergency response agencies, international organizations, locations, events, or key figures. Encourage diversity in topics: ground response, aid distribution, weather events, infrastructure failure, etc. Your output should be a Json list of about 3 strings, each describing a different NER twitter retrieval task. No explanations or extra formatting. Be concise, diverse, and realistic.",
    "tw_query": "You have been assigned an entity-tweet retrieval task: {task} Your mission is to write one example for this task in JSON format. The JSON object must include: query: a sentence that mentions one or more disaster-related entities. positive_tweet: a tweet that provides relevant and informative content about the mentioned entity or entities. hard_negative_tweet: a tweet that is topically related but does not provide any useful information about the mentioned entities. Guidelines: The query should clearly mention a recognizable entity tied to the disaster domain. The positive_tweet should be informal, observational, or emotional—realistic Twitter-style language providing relevant details about the entity. The hard_negative_tweet should be on the same topic (e.g., disaster, emergency) but not focus on the mentioned entity. All content should be inspired by disaster-related themes such as rescue missions, weather events, humanitarian aid, response coordination, etc. Your output must be a single JSON object only. No explanation, no formatting beyond JSON. Keep it realistic and natural in tone.",

    "doc_task": "Brainstorm a list of document retrieval tasks, where the goal is: Given a user query, retrieve documents that provide useful and relevant answers. Here are a few examples to get you started: Given a query about emergency evacuation procedures, retrieve a document that outlines the proper steps. Given a query asking how heatwaves affect public health, retrieve a document discussing the medical or environmental impacts. Given a query about funding for post-disaster recovery, retrieve a document describing the financial aid process. Given a query on how early warning systems reduce disaster risk, retrieve a document explaining their function and benefits. Guidelines: Each task should be a single sentence describing what the query is and what kind of document should be retrieved in response. Tasks should span a broad range of information needs, from facts to procedures to causal relationships. Focus on disaster-related themes such as risk mitigation, emergency logistics, climate impact, institutional roles, and infrastructure damage. Your output should be a Json list of 20 strings, each describing a distinct and useful text retrieval task. Only output the list. No explanations.",
    "doc_query": "You have been assigned a document retrieval task: {task}. Your mission is to write one example for this task in JSON format. The JSON object must include: user_query: a single, well-formed natural language query that clearly asks for information based on the assigned task; positive_document: a string containing the relevant document (e.g., a paragraph) that answers the query. Guidelines: The user_query should be realistic and specific to disaster management. The positive_document should be drawn from or inspired by actual disaster-related text (e.g., policies, reports, news). Output only a single JSON object with exactly these two keys and no additional content."
  
  }  
  